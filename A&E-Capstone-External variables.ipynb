{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af464f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "config = pd.read_csv('elenakosmas_accessKeys.csv') #Make sure file is saved to working directory\n",
    "access_key = config.loc[0, 'Access key ID']\n",
    "secret_key = config.loc[0, 'Secret access key']\n",
    "region = 'us-east-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb559a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awswrangler as wr #May need to pip install for first use.\n",
    "import boto3 #May need to pip install for first use.\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "962ddaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: awswrangler in /Users/elenakosmas/anaconda3/lib/python3.10/site-packages (3.9.1)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.23.32 in /Users/elenakosmas/anaconda3/lib/python3.10/site-packages (from awswrangler) (1.35.24)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/elenakosmas/anaconda3/lib/python3.10/site-packages (from awswrangler) (14.0.1)\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.2.0 in /Users/elenakosmas/anaconda3/lib/python3.10/site-packages (from awswrangler) (1.5.3)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.4.0 in /Users/elenakosmas/anaconda3/lib/python3.10/site-packages (from awswrangler) (4.9.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18 in /Users/elenakosmas/anaconda3/lib/python3.10/site-packages (from awswrangler) (1.23.5)\n",
      "Requirement already satisfied: packaging<25.0,>=21.1 in /Users/elenakosmas/anaconda3/lib/python3.10/site-packages (from awswrangler) (22.0)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.20.32 in /Users/elenakosmas/anaconda3/lib/python3.10/site-packages (from awswrangler) (1.35.24)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /Users/elenakosmas/anaconda3/lib/python3.10/site-packages (from boto3<2.0.0,>=1.20.32->awswrangler) (0.10.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/elenakosmas/anaconda3/lib/python3.10/site-packages (from boto3<2.0.0,>=1.20.32->awswrangler) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/elenakosmas/anaconda3/lib/python3.10/site-packages (from botocore<2.0.0,>=1.23.32->awswrangler) (2.8.2)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /Users/elenakosmas/anaconda3/lib/python3.10/site-packages (from botocore<2.0.0,>=1.23.32->awswrangler) (1.26.14)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/elenakosmas/anaconda3/lib/python3.10/site-packages (from pandas<3.0.0,>=1.2.0->awswrangler) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /Users/elenakosmas/anaconda3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.23.32->awswrangler) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install awswrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffc0204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#S3 Client\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=access_key,\n",
    "    aws_secret_access_key=secret_key,\n",
    "    region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0d7c5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capstone1ek\n"
     ]
    }
   ],
   "source": [
    "#Displaying all the buckets in AWS Account.\n",
    "buckets = s3_client.list_buckets()\n",
    "\n",
    "for bucket in buckets['Buckets']:\n",
    "    print(bucket['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11c47b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpv_Q12022.csv\n",
      "cpv_Q12023.csv\n",
      "cpv_Q22022.csv\n",
      "cpv_Q22023.csv\n",
      "cpv_Q32022.csv\n",
      "cpv_Q32023.csv\n",
      "cpv_Q42022.csv\n",
      "cpv_Q42023.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Go to desired bucket. \n",
    "bucket_name = 'capstone1ek'\n",
    "\n",
    "# List the objects in your bucket\n",
    "response = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "\n",
    "# Check if the response contains 'Contents'\n",
    "if 'Contents' in response:\n",
    "    # Print out the object keys\n",
    "    for obj in response['Contents']:\n",
    "        print(obj['Key'])\n",
    "else:\n",
    "    print('No objects found in the bucket.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b8b4463",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path1 = 's3://capstone1ek/cpv_Q12022.csv'\n",
    "s3_path2 = 's3://capstone1ek/cpv_Q12023.csv'\n",
    "s3_path3 = 's3://capstone1ek/cpv_Q22022.csv'\n",
    "s3_path4 = 's3://capstone1ek/cpv_Q22023.csv'\n",
    "s3_path5 = 's3://capstone1ek/cpv_Q32022.csv'\n",
    "s3_path6 = 's3://capstone1ek/cpv_Q32023.csv'\n",
    "s3_path7 = 's3://capstone1ek/cpv_Q42022.csv'\n",
    "s3_path8 = 's3://capstone1ek/cpv_Q42023.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1235ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create boto3_session for AWS Wrangler\n",
    "boto3_session = boto3.Session(\n",
    "    aws_access_key_id=access_key,\n",
    "    aws_secret_access_key=secret_key,\n",
    "    region_name=region\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f327eb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elenakosmas/anaconda3/lib/python3.10/site-packages/awswrangler/s3/_read_text_core.py:115: DtypeWarning: Columns (15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df: pd.DataFrame = parser_func(f, **pandas_kwargs)\n",
      "/Users/elenakosmas/anaconda3/lib/python3.10/site-packages/awswrangler/s3/_read_text_core.py:115: DtypeWarning: Columns (15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df: pd.DataFrame = parser_func(f, **pandas_kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Read Q1 2022 Data\n",
    "Q122_df = wr.s3.read_csv(path=s3_path1, boto3_session=boto3_session)\n",
    "# Read Q1 2023 Data\n",
    "Q123_df = wr.s3.read_csv(path=s3_path2, boto3_session=boto3_session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e01ec1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elenakosmas/anaconda3/lib/python3.10/site-packages/awswrangler/s3/_read_text_core.py:115: DtypeWarning: Columns (15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df: pd.DataFrame = parser_func(f, **pandas_kwargs)\n",
      "/Users/elenakosmas/anaconda3/lib/python3.10/site-packages/awswrangler/s3/_read_text_core.py:115: DtypeWarning: Columns (15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df: pd.DataFrame = parser_func(f, **pandas_kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Read Q2 2022 Data\n",
    "Q222_df = wr.s3.read_csv(path=s3_path3, boto3_session=boto3_session)\n",
    "# Read Q2 2023 Data\n",
    "Q223_df = wr.s3.read_csv(path=s3_path4, boto3_session=boto3_session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5db06edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elenakosmas/anaconda3/lib/python3.10/site-packages/awswrangler/s3/_read_text_core.py:115: DtypeWarning: Columns (15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df: pd.DataFrame = parser_func(f, **pandas_kwargs)\n",
      "/Users/elenakosmas/anaconda3/lib/python3.10/site-packages/awswrangler/s3/_read_text_core.py:115: DtypeWarning: Columns (15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df: pd.DataFrame = parser_func(f, **pandas_kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Read Q3 2022 Data\n",
    "Q322_df = wr.s3.read_csv(path=s3_path5, boto3_session=boto3_session)\n",
    "\n",
    "# Read Q3 2023 Data\n",
    "Q323_df = wr.s3.read_csv(path=s3_path6, boto3_session=boto3_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a579bec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elenakosmas/anaconda3/lib/python3.10/site-packages/awswrangler/s3/_read_text_core.py:115: DtypeWarning: Columns (15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df: pd.DataFrame = parser_func(f, **pandas_kwargs)\n",
      "/Users/elenakosmas/anaconda3/lib/python3.10/site-packages/awswrangler/s3/_read_text_core.py:115: DtypeWarning: Columns (15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df: pd.DataFrame = parser_func(f, **pandas_kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Read Q4 2022 Data\n",
    "Q422_df = wr.s3.read_csv(path=s3_path7, boto3_session=boto3_session)\n",
    "\n",
    "# Read Q4 2023 Data\n",
    "Q423_df = wr.s3.read_csv(path=s3_path8, boto3_session=boto3_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a9e35b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month                                object\n",
      "Year                                  int64\n",
      "Program                              object\n",
      "Program - Network                    object\n",
      "Episode                              object\n",
      "Partner - Network                    object\n",
      "Series ID                           float64\n",
      "Program ID Key                        int64\n",
      "Partner - Episode                    object\n",
      "Partner - Program                    object\n",
      "Partner - Episode Duration            int64\n",
      "Partner - Name                       object\n",
      "Partner - Platform                   object\n",
      "Partner - Device                     object\n",
      "Partner - Demo                       object\n",
      "Partner - Rating Source              object\n",
      "Partner - Viewer Code                object\n",
      "Program - Broadcast Length            int64\n",
      "Program - Broadcast Length SSSSS      int64\n",
      "Exposures                           float64\n",
      "Minutes Viewed                      float64\n",
      "Program - Current Premiere Date      object\n",
      "Program - Air Title                  object\n",
      "Program - Budget Line                object\n",
      "Program - Category                   object\n",
      "Program - Episode Number            float64\n",
      "Program - External Air Order        float64\n",
      "Program - External Season           float64\n",
      "Program - Franchise                  object\n",
      "Program - Genre Name                 object\n",
      "Program - Is Special                float64\n",
      "Program - Mega Genre                 object\n",
      "Program - Network Name               object\n",
      "Program - PAC ID                    float64\n",
      "Program - PAC Title                  object\n",
      "Program - Premiere Network Code      object\n",
      "Program - Production Year           float64\n",
      "Program - Type                       object\n",
      "Program - ID                        float64\n",
      "Program - Status                     object\n",
      "Program - Series Code                object\n",
      "Program - Series ID                 float64\n",
      "Program - Series Name                object\n",
      "Program - Long Form/Short Form       object\n",
      "Program - Sub Category               object\n",
      "Program - Supplier                   object\n",
      "Program - TMS ID                     object\n",
      "Year and Month                       object\n",
      "Partner - Data Type                  object\n",
      "Program Sub-Type                     object\n",
      "NO.of Scheduled Minutes               int64\n",
      "NO.of Telecasts                       int64\n",
      "Distinct Episode                      int64\n",
      "# of Episode                          int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([Q122_df, Q123_df,Q222_df, Q223_df,Q322_df, Q323_df,Q422_df, Q423_df,], ignore_index=True)\n",
    "\n",
    "#Check dimensions.\n",
    "df.shape\n",
    "\n",
    "\n",
    "#Check data types\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75c761df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Prepare for Data Wrangling: Notes from Sponsor\n",
    "# \n",
    "# #### Show Types to focus on: \n",
    "# 1. Legacy Series In-Premiere: Defined as a series with more than two season available. The new season is only available on 1st/2nd window platforms, but the library is available on 1st/2nd/3rd window platforms.\n",
    "# 2. New Series In-Premiere: Defined as a series with less than two seasons. Generally, they are only available on 1st/2nd window platforms. If in its 2nd season, there could be a season one available on 1st/2nd/3rd window platforms, but I can’t think of any that happened like that in FY22/FY23 (aka the data you will be working with).\n",
    "# \n",
    "# #### Show Types to exclude:\n",
    "# 1. Movies/Specials\n",
    "# 2. Non-Returning/Cancelled series (ie Dog the Bounty Hunter, and even Dance Moms eventhoug they are trying to revive that this year)\n",
    "# \n",
    "# \n",
    "# #### Ad-Sales Platforms to focus on:\n",
    "# 1. Live +7: This drives about 90% of the total Ad-Sales P2+ mins (this data is generally complete b/c it comes from Nielsen)\n",
    "# 2. Non-Linear: These top partners drive 80%-90% of the Ad-Sales Non-Linear P2+ Mins. Would try to ensure that the data here is complete and makes sense. I recently had to pull Ad-sales non-linear data for a presentation and attached was my data pull. Thought this would be helpful so you can see the scale of all the platforms at a high level.\n",
    "#     a. On Demand:\n",
    "#         (1) O&O\n",
    "#         (2) vMVPD Hulu Live: HUGE NOTE: Will explain more in person, but we have licensed a large amount of our library content to Hulu SVOD, therefore that inventory does not live on Hulu Live for ad-sales to monetize. (i.e. all Alone library lives on Hulu SVOD, and only the new Alone season is available on Hulu Live each year).\n",
    "#         (3) vMVPD Philo\n",
    "#         (4) vMVPD SlingTV\n",
    "#         (5) STB VOD4+ Comcast\n",
    "#     b. FAST: Samsung\n",
    "#     \n",
    "# #### Primary Levers to focus: \n",
    "# \n",
    "# 1. Paid Media - Sent by Cristina\n",
    "# 2. Organic Social Media (A+E under impression that Hoya 2 will retrieve this)\n",
    "# 3. Partner Earned Media (Still pending with A+E)\n",
    "# 4. O&O IFW Content - Sent by Cristina\n",
    "# 5. 3rd Windowing Platforms (FAST/SVOD/AVOD) - Available via CP Data\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb94555b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### Focusing on New / Returning Shows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "375e2942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[24]:\n",
    "\n",
    "df['Program - Current Premiere Date'] #Want to get year shows were originally premiered to determine whether\n",
    "#they are returning / actively airing\n",
    "\n",
    "# Convert the column to datetime if it's not already in datetime format\n",
    "df['Program - Current Premiere Date'] = pd.to_datetime(df['Program - Current Premiere Date'], errors='coerce')\n",
    "\n",
    "# Extract the year\n",
    "df['Premiere Year'] = df['Program - Current Premiere Date'].dt.year\n",
    "\n",
    "# Drop original column\n",
    "df = df.drop(columns=['Program - Current Premiere Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee8ef4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify shows with a premiere year in 2022 or 2023\n",
    "shows_2022_2023 = df[df['Premiere Year'].isin([2022, 2023])]['Program'].unique()\n",
    "\n",
    "# Filter the original DataFrame to keep all data for those identified shows\n",
    "df = df[df['Program'].isin(shows_2022_2023)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "264f9d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2020., 2012., 2002., 2008., 2019., 2007., 2017., 2003., 2010.,\n",
       "       2013., 2018., 2015., 2016., 2022., 2005., 2004., 2014., 2009.,\n",
       "       2006., 2021., 2011., 2000., 2001., 1999.,   nan, 1997., 1996.,\n",
       "       1998., 2023., 2024., 1992.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Premiere Year'].unique() #Ensuring that data is kept for all years if the show is newly \n",
    "#premiering in 2022/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afc93523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### Filtering out Specials and Movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08c13e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out Specials.\n",
    "df = df[df[\"Program - Is Special\"] != 1] #Removing observations where the Program is a Special.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d82cb105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., nan])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Program - Is Special\"].unique() #Remaining options include 0 and null values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aec6be90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136779"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Program - Is Special\"].isna().sum() #136k+ null values left. Dropping this column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47543a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Program - Is Special'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "056887f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Program - Type variable also seems to be indicative of a special. Continuing to filter down.\n",
    "\n",
    "df['Program - Type'].unique() #Options include Special and Series\n",
    "df = df[df[\"Program - Type\"] != \"Special\"] #Removing observations where the Program is a Special.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af7218b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Series', nan], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Program - Type'].unique() #Remaining Options include Series and Null Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3782eb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136779"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Program - Type'].isna().sum() #Because there are 136k+ null values aside from Series,\n",
    "#I am dropping this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71023b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Program - Type']) #Removing column with options for Series or NA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "554973f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out Movies and any outstanding Specials.\n",
    "\n",
    "df = df[~((df[\"Program Sub-Type\"] == \"Movie\") | (df[\"Program Sub-Type\"] == \"Special\"))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "663b3a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unscripted', 'Scripted', 'Docu-Drama', nan, 'Mini-Series'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirm remaining observation options\n",
    "df['Program Sub-Type'].unique() #Options include Scripted, Mini-Series, etc.. Keeping variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9a1d115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###### Creating new variable for Legacy/New\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35580dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new variable to establish whether season is Legacy or New\n",
    "\n",
    "# Initialize 'Series Type' column with NaN values\n",
    "df[\"Series Type\"] = np.nan\n",
    "\n",
    "# Apply 'New' to rows where 'Program - External Season' is less than 2\n",
    "df.loc[df[\"Program - External Season\"] < 2, \"Series Type\"] = \"New\"\n",
    "\n",
    "# Apply 'Legacy' to rows where 'Program - External Season' is 2 or more\n",
    "df.loc[df[\"Program - External Season\"] >= 2, \"Series Type\"] = \"Legacy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "323c12d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###### Removing columns with large amount of outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "361f779f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values:\n",
      "Program - Network                        6\n",
      "Partner - Network                     3802\n",
      "Partner - Episode                   164217\n",
      "Partner - Program                    87477\n",
      "Partner - Device                     74600\n",
      "Partner - Rating Source            5475824\n",
      "Partner - Viewer Code              5475824\n",
      "Program - Air Title                 136779\n",
      "Program - Budget Line               141164\n",
      "Program - Category                  167675\n",
      "Program - Episode Number            395410\n",
      "Program - External Air Order        324458\n",
      "Program - External Season           282290\n",
      "Program - Franchise                 815770\n",
      "Program - Genre Name                136785\n",
      "Program - Mega Genre                167675\n",
      "Program - Network Name              136779\n",
      "Program - PAC ID                    136779\n",
      "Program - PAC Title                 136779\n",
      "Program - Premiere Network Code     320014\n",
      "Program - Production Year           143892\n",
      "Program - ID                        136779\n",
      "Program - Status                    136779\n",
      "Program - Series Code               136779\n",
      "Program - Series ID                 136779\n",
      "Program - Series Name               136779\n",
      "Program - Sub Category              167675\n",
      "Program - Supplier                  136781\n",
      "Program - TMS ID                    304876\n",
      "Program Sub-Type                    152928\n",
      "Premiere Year                       314827\n",
      "Series Type                         282290\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Searching for null values:\n",
    "#Count of missing values per column\n",
    "missing_count = df.isna().sum()\n",
    "\n",
    "# Display columns with missing values\n",
    "missing_columns = missing_count[missing_count > 0]\n",
    "\n",
    "print(\"Columns with missing values:\")\n",
    "print(missing_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51cfb0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping columns with more than a million missing values\n",
    "df = df.drop(columns =['Partner - Viewer Code','Partner - Rating Source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d2f9d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There is a recurring pattern of 136779 missing values. Dropping null values to see if it resolves some\n",
    "#of the rest.\n",
    "df = df.dropna(subset=['Program - Series ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11c2e29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values:\n",
      "Program - Network                       6\n",
      "Partner - Network                    1751\n",
      "Partner - Episode                  163984\n",
      "Partner - Program                   85854\n",
      "Partner - Device                    74531\n",
      "Program - Budget Line                4385\n",
      "Program - Category                  30896\n",
      "Program - Episode Number           258631\n",
      "Program - External Air Order       187679\n",
      "Program - External Season          145511\n",
      "Program - Franchise                678991\n",
      "Program - Genre Name                    6\n",
      "Program - Mega Genre                30896\n",
      "Program - Premiere Network Code    183235\n",
      "Program - Production Year            7113\n",
      "Program - Sub Category              30896\n",
      "Program - Supplier                      2\n",
      "Program - TMS ID                   168097\n",
      "Program Sub-Type                    16149\n",
      "Premiere Year                      178048\n",
      "Series Type                        145511\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Reviewing remaining missing values\n",
    "missing_count = df.isna().sum()\n",
    "\n",
    "# Display columns with missing values\n",
    "missing_columns = missing_count[missing_count > 0]\n",
    "\n",
    "print(\"Columns with missing values:\")\n",
    "print(missing_columns) #The resulting missing values are much more manageable and will be imputed closer to\n",
    "#model training. \n",
    "\n",
    "#QUESTION FOR TEAM TO CONSIDER: Topic of how the grouping of variables in the season concatenation\n",
    "#will affect the missing value imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f00818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling NAs with \"Unknown\" and 0 for purposes of grouping. Beforehand, the grouping was removing Linear\n",
    "#variables because they had missing values in one category\n",
    "\n",
    "def fill_na(df):\n",
    "    # Fill NaN with 'Unknown' for categorical/object columns\n",
    "    df_cat = df.select_dtypes(include=['category', 'object']).fillna('Unknown')\n",
    "    \n",
    "    # Fill NaN with 0 for numerical columns\n",
    "    df_num = df.select_dtypes(include=['number']).fillna(0)\n",
    "    \n",
    "    # Combine both DataFrames\n",
    "    df_filled = pd.concat([df_cat, df_num], axis=1)\n",
    "    \n",
    "    # If there are other data types that we want to preserve, we include them here\n",
    "    df_other = df.select_dtypes(exclude=['category', 'object', 'number'])\n",
    "    \n",
    "    # Add the untouched columns (like datetime) back if any\n",
    "    if not df_other.empty:\n",
    "        df_filled = pd.concat([df_filled, df_other], axis=1)\n",
    "    \n",
    "    return df_filled\n",
    "\n",
    "# Apply the function to your DataFrame\n",
    "df_filled = fill_na(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f576b814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###### Concatenate by Season\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1099c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns relevant to the episode\n",
    "df_filled = df_filled.drop(columns=['Program - Episode Number','Program - External Air Order','Episode','# of Episode','Distinct Episode',\n",
    "                      'Year and Month','Month','Partner - Episode','Program - Air Title','Program - Budget Line'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "30f7716f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Program                              object\n",
       "Program - Network                    object\n",
       "Partner - Network                    object\n",
       "Partner - Program                    object\n",
       "Partner - Name                       object\n",
       "Partner - Platform                   object\n",
       "Partner - Device                     object\n",
       "Partner - Demo                       object\n",
       "Program - Category                   object\n",
       "Program - Franchise                  object\n",
       "Program - Genre Name                 object\n",
       "Program - Mega Genre                 object\n",
       "Program - Network Name               object\n",
       "Program - PAC Title                  object\n",
       "Program - Premiere Network Code      object\n",
       "Program - Status                     object\n",
       "Program - Series Code                object\n",
       "Program - Series Name                object\n",
       "Program - Long Form/Short Form       object\n",
       "Program - Sub Category               object\n",
       "Program - Supplier                   object\n",
       "Program - TMS ID                     object\n",
       "Partner - Data Type                  object\n",
       "Program Sub-Type                     object\n",
       "Series Type                          object\n",
       "Year                                  int64\n",
       "Series ID                           float64\n",
       "Program ID Key                        int64\n",
       "Partner - Episode Duration            int64\n",
       "Program - Broadcast Length            int64\n",
       "Program - Broadcast Length SSSSS      int64\n",
       "Exposures                           float64\n",
       "Minutes Viewed                      float64\n",
       "Program - External Season           float64\n",
       "Program - PAC ID                    float64\n",
       "Program - Production Year           float64\n",
       "Program - ID                        float64\n",
       "Program - Series ID                 float64\n",
       "NO.of Scheduled Minutes               int64\n",
       "NO.of Telecasts                       int64\n",
       "Premiere Year                       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Review variable types after column dropping\n",
    "df_filled.dtypes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9df43e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Columns: ['Program', 'Program - Network', 'Partner - Network', 'Partner - Program', 'Partner - Name', 'Partner - Platform', 'Partner - Device', 'Partner - Demo', 'Program - Category', 'Program - Franchise', 'Program - Genre Name', 'Program - Mega Genre', 'Program - Network Name', 'Program - PAC Title', 'Program - Premiere Network Code', 'Program - Status', 'Program - Series Code', 'Program - Series Name', 'Program - Long Form/Short Form', 'Program - Sub Category', 'Program - Supplier', 'Program - TMS ID', 'Partner - Data Type', 'Program Sub-Type', 'Series Type']\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = df_filled.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(\"Categorical Columns:\", categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9295abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_filled.groupby(['Program', 'Program - Network', 'Partner - Network', 'Partner - Program', \n",
    "                             'Partner - Name', 'Partner - Platform', 'Partner - Device', 'Partner - Demo',\n",
    "                             'Program - Category', 'Program - Franchise', 'Program - Genre Name', \n",
    "                             'Program - Mega Genre', 'Program - Network Name', 'Program - PAC Title', \n",
    "                             'Program - Premiere Network Code', 'Program - Status', 'Program - Series Code', \n",
    "                             'Program - Series Name', 'Program - Long Form/Short Form', 'Program - Sub Category',\n",
    "                             'Program - Supplier', 'Program - TMS ID', 'Partner - Data Type', 'Program Sub-Type',\n",
    "                             'Series Type', 'Premiere Year','Year','Series ID','Program ID Key',\n",
    "                             'Program - External Season','Program - PAC ID','Program - Production Year',\n",
    "                             'Program - ID', 'Program - Series ID'],observed=False)\n",
    "\n",
    "aggregated_seasons = grouped.agg({\n",
    "    'Partner - Episode Duration': 'sum',      \n",
    "    'Program - Broadcast Length': 'sum',\n",
    "    'Program - Broadcast Length SSSSS':'sum',\n",
    "    'Exposures':'sum',\n",
    "    'Minutes Viewed':'sum',\n",
    "    'NO.of Scheduled Minutes':'sum', \n",
    "    'NO.of Telecasts':'sum', \n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ad043ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DVR 4-7', 'Live +3', 'vMVPD VOD', 'Linear TV', 'DTC SVOD', 'DTO',\n",
       "       'MVPD Apps & Sites', 'STB VOD', 'AVOD', 'Social', 'O+O',\n",
       "       'Fast Channels', 'SVOD'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_seasons['Partner - Platform'].unique() #Confirming that the expected categories are still there\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "32a295f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(811656, 41)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_seasons.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e1a332c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ###### Filter Linear to Live+7 by adding Live +3 and DVR 4-7 together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "016d17e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sponsor wants to focus on Live +7 for Linear TV. Confirmed that Live +7 is a combination of Live+3 and\n",
    "# DVR 4-7. Removing the other linear variables.\n",
    "aggregated_seasons = aggregated_seasons[~aggregated_seasons['Partner - Platform'].isin(['Linear TV', 'Off Net Linear Licensing'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9c853e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data based on 'Partner - Platform' values\n",
    "mask = aggregated_seasons['Partner - Platform'].isin(['Live +3', 'DVR 4-7'])\n",
    "\n",
    "# Define the group columns\n",
    "group_columns = ['Program', 'Program - Network', 'Partner - Network', 'Partner - Program', \n",
    "                             'Partner - Name', 'Partner - Platform', 'Partner - Device', 'Partner - Demo',\n",
    "                             'Program - Category', 'Program - Franchise', 'Program - Genre Name', \n",
    "                             'Program - Mega Genre', 'Program - Network Name', 'Program - PAC Title', \n",
    "                             'Program - Premiere Network Code', 'Program - Status', 'Program - Series Code', \n",
    "                             'Program - Series Name', 'Program - Long Form/Short Form', 'Program - Sub Category',\n",
    "                             'Program - Supplier', 'Program - TMS ID', 'Partner - Data Type', 'Program Sub-Type',\n",
    "                             'Series Type', 'Premiere Year','Year','Series ID','Program ID Key',\n",
    "                             'Program - External Season','Program - PAC ID','Program - Production Year',\n",
    "                             'Program - ID', 'Program - Series ID']\n",
    "\n",
    "# Group by the categorical columns and sum only the numeric ones\n",
    "df_live7_subset = aggregated_seasons[mask].groupby(group_columns, as_index=False).sum(numeric_only=True)\n",
    "\n",
    "# After summing, set the 'Partner - Platform' column to 'Live+7'\n",
    "df_live7_subset['Partner - Platform'] = 'Live+7'\n",
    "\n",
    "# Combine with the rest of the data\n",
    "df_rest = aggregated_seasons[~mask]\n",
    "df_final = pd.concat([df_rest, df_live7_subset], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c2dd2d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['vMVPD VOD', 'DTC SVOD', 'DTO', 'MVPD Apps & Sites', 'STB VOD',\n",
       "       'AVOD', 'Social', 'O+O', 'Fast Channels', 'SVOD', 'Live+7'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['Partner - Platform'].unique() #Confirming that Live+7 is now showing up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "af4c7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###### Bring in Ad Sales Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1f650a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                  DTV Stream\n",
      "3                  Amazon DTC\n",
      "33                 Apple SVOD\n",
      "67                    DirecTV\n",
      "77                  ROKU SVOD\n",
      "87                        Cox\n",
      "88               Omniture DTC\n",
      "118                   Comcast\n",
      "148                Amazon DTO\n",
      "484                  Dish VOD\n",
      "504                   Freevee\n",
      "534                 Hulu Live\n",
      "633                  Sling TV\n",
      "722                 Sling VOD\n",
      "821                  Spectrum\n",
      "887                      VUDU\n",
      "947               YouTube DTO\n",
      "1007                   iTunes\n",
      "1067                   Hoopla\n",
      "1076                   CoxVod\n",
      "1113              Cablevision\n",
      "1121         Others (STB VOD)\n",
      "1125                  Verizon\n",
      "1336                    Philo\n",
      "1435                  YouTube\n",
      "1445                 Omniture\n",
      "1631                Wurl Plex\n",
      "1661                Wurl Roku\n",
      "1671             Wurl Samsung\n",
      "1681         Wurl Samsung-Hub\n",
      "1701      Wurl Samsung-mobile\n",
      "1711               Wurl Vizio\n",
      "4548           Hulu+/ Disney+\n",
      "4566                  PlutoTV\n",
      "5111          Cascada Samsung\n",
      "6811             Amazon Prime\n",
      "7938               Discovery+\n",
      "9511                     Plex\n",
      "10027               ROKU AVOD\n",
      "11340                    Tubi\n",
      "12436                    Xbox\n",
      "15591             AT&T UVerse\n",
      "36456             Portal Roku\n",
      "76041                 Peacock\n",
      "184053                     LG\n",
      "723320                 Virgin\n",
      "772138                Nielsen\n",
      "Name: Partner - Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Identify unique networks so that we can bring in Ad Sales Data\n",
    "\n",
    "unique_networks = df_final['Partner - Name'].drop_duplicates()\n",
    "\n",
    "# Display the result\n",
    "print(unique_networks) #We will need to group \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4883cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming certain names to align with ad revenue lever\n",
    "df_final['Partner - Name'] = df_final['Partner - Name'].replace({'Wurl Samsung-Hub': 'Samsung', 'Cascada Samsung': 'Samsung',\n",
    "                                                   'Wurl Samsung-mobile':'Samsung',' Wurl Samsung':'Samsung',\n",
    "                                                    'Wurl Plex':'Plex','Wurl Vizio':'Vizio'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1bcc2adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       Partner - Name Partner - Platform      Stream           FY22  \\\n",
       "0       Omniture DTC                O+O    On Demand  5.474708e+09   \n",
       "1        AT&T UVerse            STB VOD    On Demand  3.057071e+06   \n",
       "2        Cablevision            STB VOD    On Demand  6.145813e+07   \n",
       "3            Comcast            STB VOD    On Demand  4.972262e+09   \n",
       "4                Cox            STB VOD    On Demand  1.226183e+08   \n",
       "5            DirecTV            STB VOD    On Demand  5.233637e+08   \n",
       "6           Dish VOD            STB VOD    On Demand  5.129893e+08   \n",
       "7   Others (STB VOD)            STB VOD    On Demand  5.391930e+07   \n",
       "8           Spectrum            STB VOD    On Demand  7.147765e+08   \n",
       "9            Verizon            STB VOD    On Demand  2.620386e+08   \n",
       "10           Comcast  MVPD Apps & Sites    On Demand  3.063606e+08   \n",
       "11            CoxVod  MVPD Apps & Sites    On Demand  4.415697e+05   \n",
       "12           DirecTV  MVPD Apps & Sites    On Demand  3.446362e+07   \n",
       "13          Spectrum  MVPD Apps & Sites    On Demand  5.878097e+08   \n",
       "14           Verizon  MVPD Apps & Sites    On Demand  9.261699e+06   \n",
       "15        DTV Stream          vMVPD VOD    On Demand  3.922163e+08   \n",
       "16         Hulu Live          vMVPD VOD    On Demand  7.084905e+09   \n",
       "17             Philo          vMVPD VOD    On Demand  2.331078e+09   \n",
       "18          Sling TV          vMVPD VOD    On Demand  7.948135e+08   \n",
       "19           Samsung      Fast Channels      Library  7.004415e+09   \n",
       "20             Vizio      Fast Channels      Library  1.537936e+09   \n",
       "21              Plex      Fast Channels      Library  1.797605e+08   \n",
       "22          Omniture                O+O  Fast-Follow  1.735522e+09   \n",
       "23       AT&T UVerse            STB VOD  Fast-Follow  2.703535e+06   \n",
       "24       Cablevision            STB VOD  Fast-Follow  5.147987e+07   \n",
       "25           Comcast            STB VOD  Fast-Follow  1.815866e+09   \n",
       "26               Cox            STB VOD  Fast-Follow  1.035286e+08   \n",
       "27           DirecTV            STB VOD  Fast-Follow  1.186558e+08   \n",
       "28          Dish VOD            STB VOD  Fast-Follow  1.285321e+08   \n",
       "29  Others (STB VOD)            STB VOD  Fast-Follow  4.165938e+07   \n",
       "30          Spectrum            STB VOD  Fast-Follow  5.550276e+08   \n",
       "31           Verizon            STB VOD  Fast-Follow  1.581598e+08   \n",
       "32           Comcast  MVPD Apps & Sites  Fast-Follow  1.801881e+08   \n",
       "33            CoxVod  MVPD Apps & Sites  Fast-Follow  2.459602e+05   \n",
       "34           DirecTV  MVPD Apps & Sites  Fast-Follow  1.198490e+07   \n",
       "35          Spectrum  MVPD Apps & Sites  Fast-Follow  5.079090e+08   \n",
       "36           Verizon  MVPD Apps & Sites  Fast-Follow  4.716398e+06   \n",
       "37        DTV Stream          vMVPD VOD  Fast-Follow  1.086506e+08   \n",
       "38         Hulu Live          vMVPD VOD  Fast-Follow  2.729054e+09   \n",
       "39             Philo          vMVPD VOD  Fast-Follow  9.020678e+08   \n",
       "40          Sling TV          vMVPD VOD  Fast-Follow  2.924643e+08   \n",
       "41          Omniture                O+O      Library  3.739185e+09   \n",
       "42       AT&T UVerse            STB VOD      Library  3.535357e+05   \n",
       "43       Cablevision            STB VOD      Library  9.978262e+06   \n",
       "44           Comcast            STB VOD      Library  3.156396e+09   \n",
       "45               Cox            STB VOD      Library  1.908972e+07   \n",
       "46           DirecTV            STB VOD      Library  4.047079e+08   \n",
       "47          Dish VOD            STB VOD      Library  3.844572e+08   \n",
       "48  Others (STB VOD)            STB VOD      Library  1.225992e+07   \n",
       "49          Spectrum            STB VOD      Library  1.597489e+08   \n",
       "50           Verizon            STB VOD      Library  1.038788e+08   \n",
       "51           Comcast  MVPD Apps & Sites      Library  1.261725e+08   \n",
       "52            CoxVod  MVPD Apps & Sites      Library  1.956095e+05   \n",
       "53           DirecTV  MVPD Apps & Sites      Library  2.247872e+07   \n",
       "54          Spectrum  MVPD Apps & Sites      Library  7.990072e+07   \n",
       "55           Verizon  MVPD Apps & Sites      Library  4.545300e+06   \n",
       "56        DTV Stream          vMVPD VOD      Library  2.835656e+08   \n",
       "57         Hulu Live          vMVPD VOD      Library  4.355851e+09   \n",
       "58             Philo          vMVPD VOD      Library  1.429010e+09   \n",
       "59          Sling TV          vMVPD VOD      Library  5.023492e+08   \n",
       "\n",
       "            FY23     FY23%           +/-       YoY  \n",
       "0   5.945745e+09  0.131375  4.710371e+08  0.086039  \n",
       "1   1.158744e+06  0.000026 -1.898327e+06 -0.620963  \n",
       "2   4.427233e+07  0.000978 -1.718580e+07 -0.279634  \n",
       "3   3.931203e+09  0.086863 -1.041059e+09 -0.209373  \n",
       "4   1.240761e+08  0.002742  1.457782e+06  0.011889  \n",
       "5   5.470786e+08  0.012088  2.371482e+07  0.045312  \n",
       "6   1.772956e+08  0.003917 -3.356937e+08 -0.654387  \n",
       "7   3.927217e+07  0.000868 -1.464713e+07 -0.271649  \n",
       "8   5.869788e+08  0.012970 -1.277977e+08 -0.178794  \n",
       "9   2.558326e+08  0.005653 -6.205963e+06 -0.023683  \n",
       "10  1.421719e+08  0.003141 -1.641887e+08 -0.535933  \n",
       "11  8.432941e+05  0.000019  4.017244e+05  0.909764  \n",
       "12  1.675025e+07  0.000370 -1.771337e+07 -0.513973  \n",
       "13  6.363284e+08  0.014060  4.851872e+07  0.082542  \n",
       "14  3.729834e+06  0.000082 -5.531864e+06 -0.597284  \n",
       "15  4.850466e+08  0.010717  9.283032e+07  0.236681  \n",
       "16  6.621007e+09  0.146296 -4.638986e+08 -0.065477  \n",
       "17  2.155684e+09  0.047631 -1.753941e+08 -0.075242  \n",
       "18  9.303836e+08  0.020557  1.355701e+08  0.170568  \n",
       "19  1.992558e+10  0.440269  1.292117e+10  1.844718  \n",
       "20  2.318651e+09  0.051232  7.807153e+08  0.507638  \n",
       "21  3.686300e+08  0.008145  1.888696e+08  1.050674  \n",
       "22  1.837535e+09  0.240697  1.020126e+08  0.058779  \n",
       "23  7.670651e+05  0.000100 -1.936470e+06 -0.716273  \n",
       "24  3.125179e+07  0.004094 -2.022808e+07 -0.392932  \n",
       "25  1.216090e+09  0.159294 -5.997764e+08 -0.330298  \n",
       "26  8.697004e+07  0.011392 -1.655858e+07 -0.159942  \n",
       "27  1.103923e+08  0.014460 -8.263558e+06 -0.069643  \n",
       "28  2.934429e+07  0.003844 -9.918781e+07 -0.771697  \n",
       "29  2.511807e+07  0.003290 -1.654131e+07 -0.397061  \n",
       "30  3.720141e+08  0.048730 -1.830135e+08 -0.329738  \n",
       "31  9.301799e+07  0.012184 -6.514185e+07 -0.411874  \n",
       "32  7.620565e+07  0.009982 -1.039825e+08 -0.577077  \n",
       "33  5.176300e+05  0.000068  2.716698e+05  1.104527  \n",
       "34  5.462484e+06  0.000716 -6.522412e+06 -0.544219  \n",
       "35  4.613259e+08  0.060429 -4.658305e+07 -0.091715  \n",
       "36  1.812660e+06  0.000237 -2.903738e+06 -0.615669  \n",
       "37  1.140961e+08  0.014945  5.445449e+06  0.050119  \n",
       "38  2.236718e+09  0.292986 -4.923361e+08 -0.180405  \n",
       "39  6.195688e+08  0.081157 -2.824990e+08 -0.313168  \n",
       "40  3.160183e+08  0.041395  2.355401e+07  0.080536  \n",
       "41  4.108210e+09  0.109193  3.690245e+08  0.098691  \n",
       "42  3.916790e+05  0.000010  3.814334e+04  0.107891  \n",
       "43  1.302054e+07  0.000346  3.042282e+06  0.304891  \n",
       "44  2.715113e+09  0.072165 -4.412827e+08 -0.139806  \n",
       "45  3.710608e+07  0.000986  1.801636e+07  0.943773  \n",
       "46  4.366863e+08  0.011607  3.197838e+07  0.079016  \n",
       "47  1.479513e+08  0.003932 -2.365059e+08 -0.615168  \n",
       "48  1.415410e+07  0.000376  1.894177e+06  0.154502  \n",
       "49  2.149647e+08  0.005714  5.521586e+07  0.345642  \n",
       "50  1.628147e+08  0.004327  5.893589e+07  0.567353  \n",
       "51  6.596626e+07  0.001753 -6.020623e+07 -0.477174  \n",
       "52  3.256641e+05  0.000009  1.300546e+05  0.664869  \n",
       "53  1.128776e+07  0.000300 -1.119096e+07 -0.497847  \n",
       "54  1.750025e+08  0.004651  9.510176e+07  1.190249  \n",
       "55  1.917175e+06  0.000051 -2.628126e+06 -0.578207  \n",
       "56  3.709505e+08  0.009860  8.738487e+07  0.308165  \n",
       "57  4.384289e+09  0.116531  2.843756e+07  0.006529  \n",
       "58  1.536115e+09  0.040829  1.071050e+08  0.074950  \n",
       "59  6.143653e+08  0.016329  1.120161e+08  0.222984  >"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in spreadsheet provided by sponsor for Ad sales.\n",
    "adsales = pd.read_excel('LinearAdSalesbyPartner.xlsx')\n",
    "adsales.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f581523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split `df` into chunks to facilitate processing\n",
    "num_chunks = 20  # Adjust based on available memory and dataset size\n",
    "df_chunks = np.array_split(df_final, num_chunks)\n",
    "\n",
    "# Initialize an empty list to hold the merged results\n",
    "merged_results = []\n",
    "\n",
    "# Iterate over each chunk and merge with `adsales`\n",
    "for chunk in df_chunks:\n",
    "    merged_chunk = pd.merge(chunk, adsales, on=['Partner - Name', 'Partner - Platform'], how='left')\n",
    "    merged_results.append(merged_chunk)\n",
    "\n",
    "# Concatenate the merged chunks into a final DataFrame\n",
    "df_final = pd.concat(merged_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "be0f250e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Program</th>\n",
       "      <th>Program - Network</th>\n",
       "      <th>Partner - Network</th>\n",
       "      <th>Partner - Program</th>\n",
       "      <th>Partner - Name</th>\n",
       "      <th>Partner - Platform</th>\n",
       "      <th>Partner - Device</th>\n",
       "      <th>Partner - Demo</th>\n",
       "      <th>Program - Category</th>\n",
       "      <th>Program - Franchise</th>\n",
       "      <th>...</th>\n",
       "      <th>Exposures</th>\n",
       "      <th>Minutes Viewed</th>\n",
       "      <th>NO.of Scheduled Minutes</th>\n",
       "      <th>NO.of Telecasts</th>\n",
       "      <th>Stream</th>\n",
       "      <th>FY22</th>\n",
       "      <th>FY23</th>\n",
       "      <th>FY23%</th>\n",
       "      <th>+/-</th>\n",
       "      <th>YoY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#TextMeWhenYouGetHome</td>\n",
       "      <td>LIFE</td>\n",
       "      <td>AEN</td>\n",
       "      <td>#TextMeWhenYouGetHome</td>\n",
       "      <td>DTV Stream</td>\n",
       "      <td>vMVPD VOD</td>\n",
       "      <td>CTV</td>\n",
       "      <td>P2+</td>\n",
       "      <td>TRUE CRIME</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>186.177333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>On Demand</td>\n",
       "      <td>3.922163e+08</td>\n",
       "      <td>4.850466e+08</td>\n",
       "      <td>0.010717</td>\n",
       "      <td>9.283032e+07</td>\n",
       "      <td>0.236681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#TextMeWhenYouGetHome</td>\n",
       "      <td>LIFE</td>\n",
       "      <td>AEN</td>\n",
       "      <td>#TextMeWhenYouGetHome</td>\n",
       "      <td>DTV Stream</td>\n",
       "      <td>vMVPD VOD</td>\n",
       "      <td>CTV</td>\n",
       "      <td>P2+</td>\n",
       "      <td>TRUE CRIME</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>186.177333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fast-Follow</td>\n",
       "      <td>1.086506e+08</td>\n",
       "      <td>1.140961e+08</td>\n",
       "      <td>0.014945</td>\n",
       "      <td>5.445449e+06</td>\n",
       "      <td>0.050119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#TextMeWhenYouGetHome</td>\n",
       "      <td>LIFE</td>\n",
       "      <td>AEN</td>\n",
       "      <td>#TextMeWhenYouGetHome</td>\n",
       "      <td>DTV Stream</td>\n",
       "      <td>vMVPD VOD</td>\n",
       "      <td>CTV</td>\n",
       "      <td>P2+</td>\n",
       "      <td>TRUE CRIME</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>186.177333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Library</td>\n",
       "      <td>2.835656e+08</td>\n",
       "      <td>3.709505e+08</td>\n",
       "      <td>0.009860</td>\n",
       "      <td>8.738487e+07</td>\n",
       "      <td>0.308165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#TextMeWhenYouGetHome</td>\n",
       "      <td>LIFE</td>\n",
       "      <td>AEN</td>\n",
       "      <td>#TextMeWhenYouGetHome</td>\n",
       "      <td>DTV Stream</td>\n",
       "      <td>vMVPD VOD</td>\n",
       "      <td>CTV</td>\n",
       "      <td>P2+</td>\n",
       "      <td>TRUE CRIME</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>90.106421</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>On Demand</td>\n",
       "      <td>3.922163e+08</td>\n",
       "      <td>4.850466e+08</td>\n",
       "      <td>0.010717</td>\n",
       "      <td>9.283032e+07</td>\n",
       "      <td>0.236681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#TextMeWhenYouGetHome</td>\n",
       "      <td>LIFE</td>\n",
       "      <td>AEN</td>\n",
       "      <td>#TextMeWhenYouGetHome</td>\n",
       "      <td>DTV Stream</td>\n",
       "      <td>vMVPD VOD</td>\n",
       "      <td>CTV</td>\n",
       "      <td>P2+</td>\n",
       "      <td>TRUE CRIME</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>90.106421</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fast-Follow</td>\n",
       "      <td>1.086506e+08</td>\n",
       "      <td>1.140961e+08</td>\n",
       "      <td>0.014945</td>\n",
       "      <td>5.445449e+06</td>\n",
       "      <td>0.050119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Program Program - Network Partner - Network  \\\n",
       "0  #TextMeWhenYouGetHome              LIFE               AEN   \n",
       "1  #TextMeWhenYouGetHome              LIFE               AEN   \n",
       "2  #TextMeWhenYouGetHome              LIFE               AEN   \n",
       "3  #TextMeWhenYouGetHome              LIFE               AEN   \n",
       "4  #TextMeWhenYouGetHome              LIFE               AEN   \n",
       "\n",
       "       Partner - Program Partner - Name Partner - Platform Partner - Device  \\\n",
       "0  #TextMeWhenYouGetHome     DTV Stream          vMVPD VOD              CTV   \n",
       "1  #TextMeWhenYouGetHome     DTV Stream          vMVPD VOD              CTV   \n",
       "2  #TextMeWhenYouGetHome     DTV Stream          vMVPD VOD              CTV   \n",
       "3  #TextMeWhenYouGetHome     DTV Stream          vMVPD VOD              CTV   \n",
       "4  #TextMeWhenYouGetHome     DTV Stream          vMVPD VOD              CTV   \n",
       "\n",
       "  Partner - Demo Program - Category Program - Franchise  ... Exposures  \\\n",
       "0            P2+         TRUE CRIME             Unknown  ...       9.0   \n",
       "1            P2+         TRUE CRIME             Unknown  ...       9.0   \n",
       "2            P2+         TRUE CRIME             Unknown  ...       9.0   \n",
       "3            P2+         TRUE CRIME             Unknown  ...       3.0   \n",
       "4            P2+         TRUE CRIME             Unknown  ...       3.0   \n",
       "\n",
       "  Minutes Viewed NO.of Scheduled Minutes NO.of Telecasts      Stream   \\\n",
       "0     186.177333                       0               0    On Demand   \n",
       "1     186.177333                       0               0  Fast-Follow   \n",
       "2     186.177333                       0               0      Library   \n",
       "3      90.106421                       0               0    On Demand   \n",
       "4      90.106421                       0               0  Fast-Follow   \n",
       "\n",
       "           FY22          FY23     FY23%           +/-       YoY  \n",
       "0  3.922163e+08  4.850466e+08  0.010717  9.283032e+07  0.236681  \n",
       "1  1.086506e+08  1.140961e+08  0.014945  5.445449e+06  0.050119  \n",
       "2  2.835656e+08  3.709505e+08  0.009860  8.738487e+07  0.308165  \n",
       "3  3.922163e+08  4.850466e+08  0.010717  9.283032e+07  0.236681  \n",
       "4  1.086506e+08  1.140961e+08  0.014945  5.445449e+06  0.050119  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b0f19c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###### Bring in Marketing Spend Data\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "df_final['Program - Franchise'] = df_final['Program - Franchise'].str.title() #Undo All Caps Column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f266a728",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Franchise is currently \"History's Greatest\". Splitting between \"Mysteries\" and \"Heist\" to match\n",
    "#market spend spreadsheet. \n",
    "df_final.loc[df_final['Program'] == \"History's Greatest Mysteries\", \n",
    "             'Program - Franchise'] = \"History's Greatest Mysteries\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5b2f5dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Franchise is currently \"History's Greatest\". Splitting between \"Mysteries\" and \"Heist\" to match\n",
    "#market spend spreadsheet. \n",
    "df_final.loc[df_final['Program'] == \"History's Greatest Heists With Pierce Brosnan\", \n",
    "             'Program - Franchise'] = \"History's Greatest Heists\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b7665a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Franchise is currently \"Secrets of\". Splitting between \"Playboy\" and \"Skinwalker\" to match\n",
    "#market spend spreadsheet. \n",
    "df_final.loc[df_final['Program'] == \"Secrets of Playboy\", \n",
    "             'Program - Franchise'] = \"Secrets of Playboy\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "24846ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Franchise is currently \"Secrets of\". Splitting between \"Playboy\" and \"Skinwalker\" to match\n",
    "#market spend spreadsheet. \n",
    "df_final.loc[\n",
    "    (df_final['Program'] == \"The Secret of Skinwalker Ranch\") | \n",
    "    (df_final['Program'] == \"The Secret of Skinwalker Ranch: Digging Deeper\"), \n",
    "    'Program - Franchise'\n",
    "] = \"Secrets Of Skinwalker Ranch\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e10a110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting spreadsheet to make sure name formatting matches across spreadsheets\n",
    "unique_program = df_final['Program - Franchise'].drop_duplicates() #Extract franchise titles\n",
    "output_excel_path = 'uniqueprograms.xlsx' #Extract Excel to Compare with Marketing Spend\n",
    "unique_program.to_excel(output_excel_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "43d073d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Reading in Marketing Spend Data\n",
    "marketspendlinear = pd.read_excel('FormattedMarketingSpend.xlsx', sheet_name=0) #Read in Linear Tab\n",
    "marketspendatv = pd.read_excel('FormattedMarketingSpend.xlsx', sheet_name=1) #Read in ATV Tab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "acc2a9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping original dataframe by linear/nonlinear, then merging\n",
    "linear_filtered = df_final[df_final['Partner - Platform']=='Live+7'] #Filtering to Linear \n",
    "nonlinear = df_final[df_final['Partner - Platform']!='Live+7'] #Filtering to NonLinear\n",
    "linear_filtered = pd.merge(marketspendlinear, linear_filtered, on='Program - Franchise', how='left') #Join Tab1\n",
    "nonlinear = pd.merge(marketspendatv, nonlinear, on='Program - Franchise', how='left') #Join Tab2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d35bce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Rejoining Linear and Nonlinear\n",
    "df_final = pd.concat([linear_filtered,nonlinear], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "79c0a5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(555383, 50)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Current Shape\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ea5d1151",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revert missing values back from Unknown to NA\n",
    "df_final.replace('Unknown', np.nan, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "61961cd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Program - Franchise', 'Campaign Start Date', 'Campaign End Date',\n",
       "       'Spend Level', 'Program', 'Program - Network', 'Partner - Network',\n",
       "       'Partner - Program', 'Partner - Name', 'Partner - Platform',\n",
       "       'Partner - Device', 'Partner - Demo', 'Program - Category',\n",
       "       'Program - Genre Name', 'Program - Mega Genre',\n",
       "       'Program - Network Name', 'Program - PAC Title',\n",
       "       'Program - Premiere Network Code', 'Program - Status',\n",
       "       'Program - Series Code', 'Program - Series Name',\n",
       "       'Program - Long Form/Short Form', 'Program - Sub Category',\n",
       "       'Program - Supplier', 'Program - TMS ID', 'Partner - Data Type',\n",
       "       'Program Sub-Type', 'Series Type', 'Premiere Year', 'Year', 'Series ID',\n",
       "       'Program ID Key', 'Program - External Season', 'Program - PAC ID',\n",
       "       'Program - Production Year', 'Program - ID', 'Program - Series ID',\n",
       "       'Partner - Episode Duration', 'Program - Broadcast Length',\n",
       "       'Program - Broadcast Length SSSSS', 'Exposures', 'Minutes Viewed',\n",
       "       'NO.of Scheduled Minutes', 'NO.of Telecasts', 'Stream ', 'FY22', 'FY23',\n",
       "       'FY23%', '+/-', 'YoY'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ###### Getting Rid of Remaining Irrelevant Columns (In Progress)\n",
    "\n",
    "df_final.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6a7ff3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9810ffc",
   "metadata": {},
   "source": [
    "### Elena add for external IMDB variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "658e8f6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program - Franchise                 555383\n",
      "Campaign Start Date                 555383\n",
      "Campaign End Date                   555383\n",
      "Spend Level                         555383\n",
      "Program                             555360\n",
      "Program - Network                   555354\n",
      "Partner - Network                   555225\n",
      "Partner - Program                   539332\n",
      "Partner - Name                      555360\n",
      "Partner - Platform                  555360\n",
      "Partner - Device                    550942\n",
      "Partner - Demo                      555360\n",
      "Program - Category                  555360\n",
      "Program - Genre Name                555360\n",
      "Program - Mega Genre                555360\n",
      "Program - Network Name              555360\n",
      "Program - PAC Title                 555360\n",
      "Program - Premiere Network Code     521796\n",
      "Program - Status                    555360\n",
      "Program - Series Code               555360\n",
      "Program - Series Name               555360\n",
      "Program - Long Form/Short Form      555360\n",
      "Program - Sub Category              555360\n",
      "Program - Supplier                  555358\n",
      "Program - TMS ID                    522025\n",
      "Partner - Data Type                 555360\n",
      "Program Sub-Type                    549027\n",
      "Series Type                         530445\n",
      "Premiere Year                       555360\n",
      "Year                                555360\n",
      "Series ID                           555360\n",
      "Program ID Key                      555360\n",
      "Program - External Season           555360\n",
      "Program - PAC ID                    555360\n",
      "Program - Production Year           555360\n",
      "Program - ID                        555360\n",
      "Program - Series ID                 555360\n",
      "Partner - Episode Duration          555360\n",
      "Program - Broadcast Length          555360\n",
      "Program - Broadcast Length SSSSS    555360\n",
      "Exposures                           555360\n",
      "Minutes Viewed                      555360\n",
      "NO.of Scheduled Minutes             555360\n",
      "NO.of Telecasts                     555360\n",
      "Stream                              392692\n",
      "FY22                                392692\n",
      "FY23                                392692\n",
      "FY23%                               392692\n",
      "+/-                                 392692\n",
      "YoY                                 392692\n",
      "dtype: int64\n",
      "Columns have different numbers of non-null rows.\n"
     ]
    }
   ],
   "source": [
    "# Get the count of non-null values for each column\n",
    "non_null_counts = df_final.count()\n",
    "\n",
    "# Display the count for each column\n",
    "print(non_null_counts)\n",
    "\n",
    "# Check if all columns have the same number of non-null rows\n",
    "if non_null_counts.nunique() == 1:\n",
    "    print(\"All columns have the same number of non-null rows.\")\n",
    "else:\n",
    "    print(\"Columns have different numbers of non-null rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3dddc6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 555360 program names in total (including duplicates).\n",
      "There are 34 unique program names.\n"
     ]
    }
   ],
   "source": [
    "# Count the total number of program names in 'Program'\n",
    "total_program_count = df_final['Program'].count()\n",
    "\n",
    "# Display the count\n",
    "print(f\"There are {total_program_count} program names in total (including duplicates).\")\n",
    "\n",
    "# Count the number of unique program names in 'Program'\n",
    "unique_program_count = df_final['Program'].nunique()\n",
    "\n",
    "# Display the count\n",
    "print(f\"There are {unique_program_count} unique program names.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "787d942a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 34 unique program names.\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique program names in 'Program - Series Name'\n",
    "unique_program_count = df_final['Program - Series Name'].nunique()\n",
    "\n",
    "# Display the count\n",
    "print(f\"There are {unique_program_count} unique program names.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2134fd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 555383 program names in total (including duplicates).\n",
      "There are 31 unique program names.\n"
     ]
    }
   ],
   "source": [
    "# Count the total number of program names in 'Program'\n",
    "total_program_count = df_final['Program - Franchise'].count()\n",
    "\n",
    "# Display the count\n",
    "print(f\"There are {total_program_count} program names in total (including duplicates).\")\n",
    "\n",
    "# Count the number of unique program names in 'Program - Series Name'\n",
    "unique_program_count = df_final['Program - Franchise'].nunique()\n",
    "\n",
    "# Display the count\n",
    "print(f\"There are {unique_program_count} unique program names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e40ed9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Program IMDb Rating\n",
      "0                          Gabby Petito         5.4\n",
      "1                            That Built         8.4\n",
      "2                            Pawn Stars         7.2\n",
      "3                   Curse Of Oak Island         6.8\n",
      "4             It's a Wonderful Lifetime         N/A\n",
      "5                Married at First Sight         6.2\n",
      "6                       Notorious Women         N/A\n",
      "7                           The Accused         7.1\n",
      "8             History'S Greatest Heists         7.5\n",
      "9                                   Wwe         7.8\n",
      "10         History'S Greatest Mysteries         6.8\n",
      "11                       History's GOAT         N/A\n",
      "12                             Cam/Wars         N/A\n",
      "13          Secrets Of Skinwalker Ranch         N/A\n",
      "14                 Voices of a Lifetime         N/A\n",
      "15                           60 Days In         7.6\n",
      "16                           Vc Andrews         5.8\n",
      "17                         Dark Marvels         7.3\n",
      "18                         Mountain Men         5.9\n",
      "19                      Ancient Empires         7.3\n",
      "20                    Highway to Heaven         6.8\n",
      "21                Baking Spirits Bright         5.2\n",
      "22            A Christmas Dance Reunion         6.1\n",
      "23                       Janet Jackson.         7.7\n",
      "24                                Alone         6.2\n",
      "25               Biography: Bobby Brown         N/A\n",
      "26               Married At First Sight         6.2\n",
      "27                   A New Orleans Noel         5.8\n",
      "28                              Accused         7.0\n",
      "29  Greatest Heists with Pierce Brosnan         N/A\n",
      "30                   Secrets Of Playboy         6.8\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Your OMDb API key\n",
    "api_key = \"9d02b21f\"\n",
    "\n",
    "# Assuming your DataFrame is named df_final and the column with series names is 'Program'\n",
    "# Extract the unique program names\n",
    "\n",
    "program_titles = df_final['Program - Franchise'].unique()\n",
    "\n",
    "# Create an empty list to store show titles and IMDb ratings\n",
    "imdb_ratings = []\n",
    "\n",
    "# Loop through each program title in the DataFrame\n",
    "for title in program_titles:\n",
    "    url = f\"http://www.omdbapi.com/?t={title}&apikey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Extract IMDb rating, if available\n",
    "    if \"imdbRating\" in data:\n",
    "        imdb_rating = data['imdbRating']\n",
    "    else:\n",
    "        imdb_rating = \"N/A\"  # If rating is not available\n",
    "\n",
    "    # Append the program title and IMDb rating to the list\n",
    "    imdb_ratings.append({\"Program\": title, \"IMDb Rating\": imdb_rating})\n",
    "\n",
    "# Convert the list of IMDb ratings to a DataFrame\n",
    "ratings_df = pd.DataFrame(imdb_ratings)\n",
    "\n",
    "# Display the Series Name (Program) and IMDb Rating\n",
    "print(ratings_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4dc9cc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Program - Franchise', 'Campaign Start Date', 'Campaign End Date',\n",
      "       'Spend Level', 'Program', 'Program - Network', 'Partner - Network',\n",
      "       'Partner - Program', 'Partner - Name', 'Partner - Platform',\n",
      "       'Partner - Device', 'Partner - Demo', 'Program - Category',\n",
      "       'Program - Genre Name', 'Program - Mega Genre',\n",
      "       'Program - Network Name', 'Program - PAC Title',\n",
      "       'Program - Premiere Network Code', 'Program - Status',\n",
      "       'Program - Series Code', 'Program - Series Name',\n",
      "       'Program - Long Form/Short Form', 'Program - Sub Category',\n",
      "       'Program - Supplier', 'Program - TMS ID', 'Partner - Data Type',\n",
      "       'Program Sub-Type', 'Series Type', 'Premiere Year', 'Year', 'Series ID',\n",
      "       'Program ID Key', 'Program - External Season', 'Program - PAC ID',\n",
      "       'Program - Production Year', 'Program - ID', 'Program - Series ID',\n",
      "       'Partner - Episode Duration', 'Program - Broadcast Length',\n",
      "       'Program - Broadcast Length SSSSS', 'Exposures', 'Minutes Viewed',\n",
      "       'NO.of Scheduled Minutes', 'NO.of Telecasts', 'Stream ', 'FY22', 'FY23',\n",
      "       'FY23%', '+/-', 'YoY', 'Holidays During Campaign'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Display all column names in df_final\n",
    "print(df_final.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac08d93",
   "metadata": {},
   "source": [
    "#### There are repeated titles - dont know how to fix this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "fd60b1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Program - Series Name Campaign Start Date Campaign End Date  \\\n",
      "94      The Food That Built America          2022-10-13        2022-11-06   \n",
      "83469                         Alone          2022-05-27        2022-06-29   \n",
      "533373                   60 Days In          2023-06-16        2023-07-02   \n",
      "242816                 Mountain Men          2022-09-02        2022-09-30   \n",
      "249191                 Mountain Men          2022-09-02        2022-09-30   \n",
      "\n",
      "                                 Holidays During Campaign  \n",
      "94                                             No Holiday  \n",
      "83469   Memorial Day, Juneteenth National Independence...  \n",
      "533373               Juneteenth National Independence Day  \n",
      "242816                                          Labor Day  \n",
      "249191                                          Labor Day  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_final has 'Campaign Start Date' and 'Campaign End Date'\n",
    "df_final['Campaign Start Date'] = pd.to_datetime(df_final['Campaign Start Date'])\n",
    "df_final['Campaign End Date'] = pd.to_datetime(df_final['Campaign End Date'])\n",
    "\n",
    "# Define the holiday data for 2022 and 2023 (as shown in your example)\n",
    "holidays = [\n",
    "    {\"Date\": \"2022-01-01\", \"Holiday Name\": \"New Year's Day\"},\n",
    "    {\"Date\": \"2022-01-17\", \"Holiday Name\": \"Martin Luther King Jr. Day\"},\n",
    "    {\"Date\": \"2022-02-14\", \"Holiday Name\": \"Valentine's Day\"},\n",
    "    {\"Date\": \"2022-02-21\", \"Holiday Name\": \"Presidents' Day\"},\n",
    "    {\"Date\": \"2022-04-17\", \"Holiday Name\": \"Easter Sunday\"},\n",
    "    {\"Date\": \"2022-05-30\", \"Holiday Name\": \"Memorial Day\"},\n",
    "    {\"Date\": \"2022-06-19\", \"Holiday Name\": \"Juneteenth National Independence Day\"},\n",
    "    {\"Date\": \"2022-07-04\", \"Holiday Name\": \"Independence Day\"},\n",
    "    {\"Date\": \"2022-09-05\", \"Holiday Name\": \"Labor Day\"},\n",
    "    {\"Date\": \"2022-10-10\", \"Holiday Name\": \"Columbus Day\"},\n",
    "    {\"Date\": \"2022-11-11\", \"Holiday Name\": \"Veterans Day\"},\n",
    "    {\"Date\": \"2022-11-24\", \"Holiday Name\": \"Thanksgiving Day\"},\n",
    "    {\"Date\": \"2022-12-25\", \"Holiday Name\": \"Christmas Day\"},\n",
    "    {\"Date\": \"2023-01-01\", \"Holiday Name\": \"New Year's Day\"},\n",
    "    {\"Date\": \"2023-01-16\", \"Holiday Name\": \"Martin Luther King Jr. Day\"},\n",
    "    {\"Date\": \"2023-02-14\", \"Holiday Name\": \"Valentine's Day\"},\n",
    "    {\"Date\": \"2023-02-20\", \"Holiday Name\": \"Presidents' Day\"},\n",
    "    {\"Date\": \"2023-04-09\", \"Holiday Name\": \"Easter Sunday\"},\n",
    "    {\"Date\": \"2023-05-29\", \"Holiday Name\": \"Memorial Day\"},\n",
    "    {\"Date\": \"2023-06-19\", \"Holiday Name\": \"Juneteenth National Independence Day\"},\n",
    "    {\"Date\": \"2023-07-04\", \"Holiday Name\": \"Independence Day\"},\n",
    "    {\"Date\": \"2023-09-04\", \"Holiday Name\": \"Labor Day\"},\n",
    "    {\"Date\": \"2023-10-09\", \"Holiday Name\": \"Columbus Day\"},\n",
    "    {\"Date\": \"2023-11-10\", \"Holiday Name\": \"Veterans Day (observed)\"},\n",
    "    {\"Date\": \"2023-11-23\", \"Holiday Name\": \"Thanksgiving Day\"},\n",
    "    {\"Date\": \"2023-12-25\", \"Holiday Name\": \"Christmas Day\"}\n",
    "]\n",
    "\n",
    "# Convert the holiday list to a DataFrame\n",
    "holidays_df = pd.DataFrame(holidays)\n",
    "\n",
    "# Convert 'Date' column to datetime type\n",
    "holidays_df['Date'] = pd.to_datetime(holidays_df['Date'])\n",
    "\n",
    "# Check if a holiday occurred during the campaign\n",
    "def holiday_during_campaign(start_date, end_date):\n",
    "    # Filter holidays that occurred between the start and end date\n",
    "    holiday_in_range = holidays_df[(holidays_df['Date'] >= start_date) & (holidays_df['Date'] <= end_date)]\n",
    "    if not holiday_in_range.empty:\n",
    "        return ', '.join(holiday_in_range['Holiday Name'].tolist())  # Return the holidays during the campaign\n",
    "    else:\n",
    "        return \"No Holiday\"\n",
    "\n",
    "# Randomly sample 500 shows from df_final\n",
    "random_500_shows = df_final.sample(500)\n",
    "\n",
    "# Apply the holiday check function to the sampled 100 shows\n",
    "random_500_shows['Holidays During Campaign'] = random_500_shows.apply(\n",
    "    lambda row: holiday_during_campaign(row['Campaign Start Date'], row['Campaign End Date']), axis=1\n",
    ")\n",
    "\n",
    "# Display the result with the holidays that occurred during the campaign for the random 100 shows\n",
    "print(random_500_shows[['Program - Series Name', 'Campaign Start Date', 'Campaign End Date', 'Holidays During Campaign']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5786f557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Program - Series Name                               Holidays During Campaign\n",
      "                                 Pawn Stars                                           Veterans Day\n",
      "                               Mountain Men                                              Labor Day\n",
      "                                 Pawn Stars                                           Veterans Day\n",
      "                     Married at First Sight                                             No Holiday\n",
      "                                 60 Days In                                             No Holiday\n",
      "                                 Pawn Stars                                           Veterans Day\n",
      "                    The Curse of Oak Island                                             No Holiday\n",
      "                                 Pawn Stars                                           Veterans Day\n",
      "                             WWE Smack Talk                                             No Holiday\n",
      "                               Mountain Men                                              Labor Day\n",
      "                    The Curse of Oak Island                                       Thanksgiving Day\n",
      "                                 Pawn Stars                                           Veterans Day\n",
      "                                 Pawn Stars                                           Veterans Day\n",
      "           Flowers in the Attic: The Origin                                             No Holiday\n",
      "                                 Pawn Stars                                           Veterans Day\n",
      "                                 Pawn Stars                                           Veterans Day\n",
      "                                 Pawn Stars                                           Veterans Day\n",
      "                                      Alone Juneteenth National Independence Day, Independence Day\n",
      "                     Married at First Sight                                             No Holiday\n",
      "                                 Pawn Stars                                           Veterans Day\n",
      "                                 Pawn Stars                                           Veterans Day\n",
      "                                 Pawn Stars                                           Veterans Day\n",
      "                                 Pawn Stars                                           Veterans Day\n",
      "                     Biography: WWE Legends                                        Presidents' Day\n",
      "                        Pawn Stars: Best Of                                           Veterans Day\n",
      "                        The Fast History Of                                             No Holiday\n",
      "                                      Alone     Memorial Day, Juneteenth National Independence Day\n",
      "                                      Alone Juneteenth National Independence Day, Independence Day\n",
      "                                      Alone     Memorial Day, Juneteenth National Independence Day\n",
      "                    The Curse of Oak Island                                             No Holiday\n",
      "                                      Alone     Memorial Day, Juneteenth National Independence Day\n",
      "                     Married at First Sight                                             No Holiday\n",
      "                               Mountain Men                                              Labor Day\n",
      "                              Alone: Frozen     Memorial Day, Juneteenth National Independence Day\n",
      "                               Mountain Men                                              Labor Day\n",
      "                      Pawn Stars Do America                                           Veterans Day\n",
      "                                 Pawn Stars                                           Veterans Day\n",
      "                                 60 Days In                                             No Holiday\n",
      "                                 Pawn Stars                                           Veterans Day\n",
      "                                      Alone     Memorial Day, Juneteenth National Independence Day\n",
      "                The Toys That Built America                                             No Holiday\n",
      "                                 60 Days In                   Juneteenth National Independence Day\n",
      "                Alone: The Skills Challenge Juneteenth National Independence Day, Independence Day\n",
      "                    The Curse of Oak Island                                       Thanksgiving Day\n",
      "                                      Alone Juneteenth National Independence Day, Independence Day\n",
      "                                      Alone Juneteenth National Independence Day, Independence Day\n",
      "                                 60 Days In                   Juneteenth National Independence Day\n",
      "                                 60 Days In                                             No Holiday\n",
      "                      Pawn Stars Do America                                           Veterans Day\n",
      "                               Mountain Men                                              Labor Day\n",
      "                               Mountain Men                                              Labor Day\n",
      "                                 Pawn Stars                                           Veterans Day\n",
      "                                 Pawn Stars                                           Veterans Day\n",
      "                    The Curse of Oak Island                                       Thanksgiving Day\n",
      "                                      Alone Juneteenth National Independence Day, Independence Day\n",
      "                    The Curse of Oak Island                                             No Holiday\n",
      "                     Married at First Sight                                             No Holiday\n",
      "                               Mountain Men                                              Labor Day\n",
      "                               Mountain Men                                              Labor Day\n",
      "                                 60 Days In                   Juneteenth National Independence Day\n",
      "                                      Alone Juneteenth National Independence Day, Independence Day\n",
      "                                      Alone     Memorial Day, Juneteenth National Independence Day\n",
      "                               Mountain Men                                              Labor Day\n",
      "                    The Curse of Oak Island                                       Thanksgiving Day\n",
      "                                 60 Days In                                             No Holiday\n",
      "                                 Pawn Stars                                           Veterans Day\n",
      "                     Married at First Sight                                             No Holiday\n",
      "                                 Pawn Stars                                           Veterans Day\n",
      "                               Mountain Men                                              Labor Day\n",
      "                               Mountain Men                                              Labor Day\n",
      "                                 Pawn Stars                                           Veterans Day\n",
      "                        Pawn Stars: Best Of                                           Veterans Day\n",
      "Married at First Sight: Afterparty + Extras                                             No Holiday\n",
      "                               Mountain Men                                              Labor Day\n",
      "                WWE's Most Wanted Treasures                                             No Holiday\n",
      "                    The Curse of Oak Island                                       Thanksgiving Day\n",
      "                     Married at First Sight                                             No Holiday\n",
      "Married at First Sight: Afterparty + Extras                                             No Holiday\n",
      "                                 Pawn Stars                                           Veterans Day\n",
      "                                 60 Days In                   Juneteenth National Independence Day\n",
      "                     Married at First Sight                                             No Holiday\n",
      "                                      Alone     Memorial Day, Juneteenth National Independence Day\n",
      "                                 WWE Rivals                                        Presidents' Day\n",
      "                                      Alone     Memorial Day, Juneteenth National Independence Day\n",
      "                     Married at First Sight                                             No Holiday\n",
      "                                 WWE Rivals                                             No Holiday\n",
      "                    The Curse of Oak Island                                       Thanksgiving Day\n",
      "                     Biography: WWE Legends                                             No Holiday\n",
      "                    The Curse of Oak Island                                       Thanksgiving Day\n",
      "                               Mountain Men                                              Labor Day\n",
      "                             WWE Smack Talk                                             No Holiday\n",
      "                                 60 Days In                   Juneteenth National Independence Day\n",
      "                    The Curse of Oak Island                                       Thanksgiving Day\n",
      "                               Mountain Men                                              Labor Day\n",
      "                                      Alone Juneteenth National Independence Day, Independence Day\n",
      "                     Married at First Sight                                             No Holiday\n",
      "                                 60 Days In                   Juneteenth National Independence Day\n",
      "                     Married at First Sight                                             No Holiday\n",
      "                                 Pawn Stars                                           Veterans Day\n",
      "                                      Alone     Memorial Day, Juneteenth National Independence Day\n"
     ]
    }
   ],
   "source": [
    "# Reset the index to remove the original index column\n",
    "result_reset = result.reset_index(drop=True)\n",
    "\n",
    "# Display the cleaned-up table without index\n",
    "print(result_reset.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094930c7",
   "metadata": {},
   "source": [
    "### Clean more: \n",
    "\n",
    "- Delete: Partner - Demo\n",
    "- Delete: Program - TMS ID, Program ID Key, Program - PAC ID / keep Program - Series ID\n",
    "- Choose: Program - Network Name and Partner - Network\n",
    "- Partner - Data Type and Partner - Platform / just keep partner platform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c79651c",
   "metadata": {},
   "source": [
    "### Relevant:\n",
    "\n",
    "Program - Franchise: Shows that are part of a successful franchise often have a better chance of performing well.\n",
    "\n",
    "Program - Genre Name, Program - Mega Genre: The genre of a show is critical in determining its audience and success potential.\n",
    "\n",
    "Program - Premiere Network Code: The network can have a large impact on show success, especially when evaluating shows across multiple networks.\n",
    "\n",
    "Program - Long Form/Short Form: The format (long/short) might affect how certain audiences engage with the content.\n",
    "\n",
    "Program - Category, Program - Sub Category: Specific categorization can provide insights into the niche or mainstream appeal of a show.\n",
    "\n",
    "Exposures, Minutes Viewed, NO.of Telecasts: Historical viewership data can be predictive of future show success, especially if you’re looking at similar types of content.\n",
    "\n",
    "Program - Production Year: Understanding the production timeline might help track trends in content that succeed based on the year they were produced.\n",
    "\n",
    "Program - Series Name, Program - Series Code: Series names and codes are essential for tracking specific show performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d188eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
